````markdown
# char-descriptor-lab  
*Генератор репрезентативного датасета описаний персонажей для задач
автоматизированной оценки в художественной прозе*  

---

## 0. Научный контекст и происхождение проекта

**Учреждение**  
Национальный исследовательский Томский государственный университет  
(НИ ТГУ, ФИПЛ, магистерская программа «Анализ естественного языка (NLP)  
в лингвистике и IT)».

**Автор**  
Бирюков Владислав Михайлович  
*(магистерская ВКР, направление — 45.04.03 «Фундаментальная и прикладная
лингвистика»).*

**Тема ВКР**  
> *Разработка модели оценки степени детализации описаний персонажей и
> локаций для литературных произведений.*

Данный репозиторий содержит весь воспроизводимый код,
использованный в **Главе 3** диссертационного исследования  
для генерации синтетического корпуса описаний **персонажей**.  
Отдельный репозиторий `loc-descriptor-lab` посвящён генерации датасета
описаний локаций.

---

## 1. Краткое описание

`char-descriptor-lab` — это полностью автоматизированный пайплайн,
который:

1. **Генерирует** описания персонажей трёх уровней «литературной
   детализации» (1 ★ / 2 ★ / 3 ★) при помощи LLM-API.
2. **Балансирует** выборку по 70 + актуальным жанрам (Book-Tok &
   industry trends 2024/25) ― см. `dataset_generator/genres.py`.
3. **Валидирует** тексты (мягкий / строгий режим) и сохраняет
   статистику.
4. Сохраняет уровневые CSV и объединённый
   `complete_dataset.csv`, пригодный для последующего обучения ML-модели.

Архитектура спроектирована так, чтобы **без изменений логики**
переиспользовать её для локаций или любых других сущностей.

---

## 2. Быстрый старт

```bash
git clone https://github.com/<your-login>/char-descriptor-lab.git
cd char-descriptor-lab
python -m venv venv && source venv/bin/activate
pip install -r requirements.txt

# Тестовый прогон (по одному описанию на каждый уровень)
python dataset_generator/main.py --test
````

▶️ **Полноценная генерация** (3 000 описаний на уровень):
`python dataset_generator/main.py`

Дополнительные опции — см. `--help`.

---

## 3. Структура проекта

```
dataset_generator/
├── main.py            # CLI-точка входа
├── config.py          # все параметры эксперимента
├── generator.py       # ядро LLM-генерации + логика батчей
├── validator.py       # мягкий/строгий валидатор синтетики
├── genres.py          # 70+ жанров с весами Book-Tok 2024/25
├── prompts.py         # system/user-prompts для 3 уровней ★
├── utils.py           # логирование, отчёты, вспомогательные вещи
└── requirements.txt   # зависимости (OpenAI SDK, pandas, NLTK …)

logs/                  # runtime-логи
generated_dataset/     # итоговые CSV + summary_report.json
```

---

## 4. Конфигурация

Все основные параметры (модель, batch-size, температуры, ограничения по
длине) задаются в `config.py`.
Для запуска нужны **только**:

```bash
export OPENAI_API_KEY="sk-..."
python dataset_generator/main.py
```

Ключ также можно прописать прямо в `config.py` (не рекомендуется для
публичных репо).

---

## 5. Воспроизводимость

* Код **не изменён** по сравнению с финальной версией,
  использованной в магистерской работе;
* Все функции и сигнатуры сохранены;
* Для фиксации результатов в статье используйте тэг
  **v1.0.0-thesis**.

---

